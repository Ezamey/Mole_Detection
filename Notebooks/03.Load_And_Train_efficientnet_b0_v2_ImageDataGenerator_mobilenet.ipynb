{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T16:18:04.414271Z",
     "start_time": "2021-03-22T16:18:01.350260Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets\n",
    "from keras.models import Sequential\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "#!pip install -U efficientnet\n",
    "from keras import layers\n",
    "from keras import regularizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T16:18:05.195974Z",
     "start_time": "2021-03-22T16:18:04.426513Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T16:18:05.688804Z",
     "start_time": "2021-03-22T16:18:05.198412Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils.np_utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T16:18:05.768598Z",
     "start_time": "2021-03-22T16:18:05.690994Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T16:18:05.792531Z",
     "start_time": "2021-03-22T16:18:05.771624Z"
    }
   },
   "outputs": [],
   "source": [
    "# Some constant\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224\n",
    "LABEL_MODE = \"categorical\"\n",
    "MODEL_NAME = \"mobilenet_b0_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T16:18:05.836089Z",
     "start_time": "2021-03-22T16:18:05.818353Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Begnin', 'Maligne']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "labels = [\"Begnin\", \"Maligne\"]\n",
    "NB_CLASS = len(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T16:18:05.872803Z",
     "start_time": "2021-03-22T16:18:05.863719Z"
    }
   },
   "outputs": [],
   "source": [
    "def Dataset_loader(DIR, RESIZE):\n",
    "    IMG = []\n",
    "    read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n",
    "    for IMAGE_NAME in tqdm(os.listdir(DIR)):\n",
    "        PATH = os.path.join(DIR,IMAGE_NAME)\n",
    "        _, ftype = os.path.splitext(PATH)\n",
    "        if ftype == \".BMP\":\n",
    "            img = read(PATH)\n",
    "            img = cv2.resize(img, (RESIZE,RESIZE))\n",
    "            IMG.append(np.array(img)/255.)\n",
    "    return IMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T16:18:21.668378Z",
     "start_time": "2021-03-22T16:18:05.876125Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 454/454 [00:00<00:00, 881.40it/s]\n",
      "100%|██████████| 503/503 [00:01<00:00, 281.36it/s]\n",
      "100%|██████████| 454/454 [00:02<00:00, 189.29it/s]\n",
      "100%|██████████| 503/503 [00:02<00:00, 222.00it/s]\n"
     ]
    }
   ],
   "source": [
    "#benign_train = np.array(Dataset_loader(\"../data/preprocessed/img/Train/Begnin/\",IMG_SIZE))\n",
    "#malign_train = np.array(Dataset_loader(\"../data/preprocessed/img/Train/Maligne/\",IMG_SIZE))\n",
    "benign_val = np.array(Dataset_loader(\"../data/preprocessed/img/Validation/Begnin/\",IMG_SIZE))\n",
    "malign_val = np.array(Dataset_loader(\"../data/preprocessed/img/Validation/Maligne/\",IMG_SIZE))\n",
    "benign_test = np.array(Dataset_loader(\"../data/preprocessed/img/Test/Begnin/\",IMG_SIZE))\n",
    "malign_test = np.array(Dataset_loader(\"../data/preprocessed/img/Test/Maligne/\",IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T16:18:36.327964Z",
     "start_time": "2021-03-22T16:18:21.671727Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create labels\n",
    "#benign_train_label = np.zeros(len(benign_train))\n",
    "#malign_train_label = np.ones(len(malign_train))\n",
    "benign_val_label = np.zeros(len(benign_val))\n",
    "malign_val_label = np.ones(len(malign_val))\n",
    "benign_test_label = np.zeros(len(benign_test))\n",
    "malign_test_label = np.ones(len(malign_test))\n",
    "#\n",
    "## Merge data \n",
    "#X_train = np.concatenate((benign_train, malign_train), axis = 0)\n",
    "#y_train = np.concatenate((benign_train_label, malign_train_label), axis = 0)\n",
    "X_val = np.concatenate((benign_val, malign_val), axis = 0)\n",
    "y_val = np.concatenate((benign_val_label, malign_val_label), axis = 0)\n",
    "X_test = np.concatenate((benign_test, malign_test), axis = 0)\n",
    "y_test = np.concatenate((benign_test_label, malign_test_label), axis = 0)\n",
    "#\n",
    "## Shuffle train data\n",
    "#s = np.arange(X_train.shape[0])\n",
    "#np.random.shuffle(s)\n",
    "#X_train = X_train[s]\n",
    "#y_train = y_train[s]\n",
    "#\n",
    "## Shuffle validation data\n",
    "s = np.arange(X_val.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X_val = X_val[s]\n",
    "y_val = y_val[s]\n",
    "#\n",
    "## Shuffle test data\n",
    "s = np.arange(X_test.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X_test = X_test[s]\n",
    "y_test = y_test[s]\n",
    "#\n",
    "## one hot encoding \n",
    "#y_train = to_categorical(y_train, num_classes=NB_CLASS)\n",
    "y_test = to_categorical(y_test, num_classes=NB_CLASS)\n",
    "y_val = to_categorical(y_val, num_classes=NB_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T16:18:36.387698Z",
     "start_time": "2021-03-22T16:18:36.344346Z"
    }
   },
   "outputs": [],
   "source": [
    "# data augmentation - cut out \n",
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "\n",
    "    return eraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T16:18:50.739199Z",
     "start_time": "2021-03-22T16:18:50.704084Z"
    }
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=45,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.1, # Randomly zoom image \n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=True,  # randomly flip images\n",
    "    preprocessing_function=get_random_eraser(p=0.5, v_h=0, s_h=0.25),\n",
    "    rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T16:18:57.081573Z",
     "start_time": "2021-03-22T16:18:53.262674Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nmobilenet_1.00_224 (Function (None, 7, 7, 1024)        3228864   \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 1024)              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               131200    \n_________________________________________________________________\ndropout (Dropout)            (None, 128)               0         \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 128)               512       \n_________________________________________________________________\ndense_1 (Dense)              (None, 2)                 258       \n=================================================================\nTotal params: 3,360,834\nTrainable params: 3,338,690\nNon-trainable params: 22,144\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobilenet = MobileNet(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "model=Sequential()\n",
    "model.add(mobilenet)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(NB_CLASS, activation='softmax'))\n",
    "\n",
    "alpha = 1e-3  # weight decay coefficient\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
    "        layer.add_loss(lambda: keras.regularizers.l2(alpha)(layer.kernel))\n",
    "    if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
    "        layer.add_loss(lambda: keras.regularizers.l2(alpha)(layer.bias))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T16:18:57.096962Z",
     "start_time": "2021-03-22T16:18:57.086965Z"
    }
   },
   "outputs": [],
   "source": [
    "# callback - if accuracy doesn't improve after 3 epoch then reduce lr by factor 0.5 \n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,patience=3, min_lr=0.000005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T16:19:00.707991Z",
     "start_time": "2021-03-22T16:19:00.696701Z"
    }
   },
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc, tp = self.model.evaluate(x, y, verbose=1)\n",
    "        print('\\nTesting loss: {}, acc: {}, TP:{}\\n'.format(loss, acc, tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T16:19:03.521427Z",
     "start_time": "2021-03-22T16:19:03.482579Z"
    }
   },
   "outputs": [],
   "source": [
    "# compile the model \n",
    "optimizer=optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer,loss=\"binary_crossentropy\", metrics=[\"accuracy\", tf.keras.metrics.TruePositives()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T15:17:25.037469Z",
     "start_time": "2021-03-22T15:17:25.021871Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T19:00:00.558120Z",
     "start_time": "2021-03-22T16:36:11.341819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2873 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "90/90 [==============================] - 789s 9s/step - loss: 0.5854 - accuracy: 0.7177 - true_positives: 2062.0000 - val_loss: 0.9289 - val_accuracy: 0.5120 - val_true_positives: 490.0000\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 841s 9s/step - loss: 0.5310 - accuracy: 0.7539 - true_positives: 2166.0000 - val_loss: 0.8191 - val_accuracy: 0.6520 - val_true_positives: 624.0000\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 857s 9s/step - loss: 0.5145 - accuracy: 0.7511 - true_positives: 2158.0000 - val_loss: 1.1119 - val_accuracy: 0.6688 - val_true_positives: 640.0000\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 848s 9s/step - loss: 0.4772 - accuracy: 0.7825 - true_positives: 2248.0000 - val_loss: 0.4658 - val_accuracy: 0.7827 - val_true_positives: 749.0000\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 796s 9s/step - loss: 0.4856 - accuracy: 0.7734 - true_positives: 2222.0000 - val_loss: 0.6430 - val_accuracy: 0.7064 - val_true_positives: 676.0000\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 994s 11s/step - loss: 0.4595 - accuracy: 0.7905 - true_positives: 2271.0000 - val_loss: 0.8010 - val_accuracy: 0.7398 - val_true_positives: 708.0000\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 1099s 12s/step - loss: 0.4377 - accuracy: 0.8054 - true_positives: 2314.0000 - val_loss: 0.7828 - val_accuracy: 0.7137 - val_true_positives: 683.0000\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 830s 9s/step - loss: 0.4056 - accuracy: 0.8176 - true_positives: 2349.0000 - val_loss: 0.4466 - val_accuracy: 0.8067 - val_true_positives: 772.0000\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 779s 9s/step - loss: 0.3798 - accuracy: 0.8308 - true_positives: 2387.0000 - val_loss: 0.4479 - val_accuracy: 0.7962 - val_true_positives: 762.0000\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 795s 9s/step - loss: 0.3510 - accuracy: 0.8468 - true_positives: 2433.0000 - val_loss: 0.4694 - val_accuracy: 0.7983 - val_true_positives: 764.0000\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(datagen.flow_from_directory(\"../data/preprocessed/img/Train\",\n",
    "                                                target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                                class_mode='categorical',\n",
    "                                                batch_size=32,\n",
    "                                                shuffle=True),\n",
    "                    epochs=10, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:15:59.305834Z",
     "start_time": "2021-03-22T20:54:40.175023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2873 images belonging to 2 classes.\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 768s 8s/step - loss: 0.3328 - accuracy: 0.8667 - true_positives: 2490.0000 - val_loss: 0.4975 - val_accuracy: 0.7962 - val_true_positives: 762.0000\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 758s 8s/step - loss: 0.3322 - accuracy: 0.8594 - true_positives: 2469.0000 - val_loss: 0.5184 - val_accuracy: 0.8182 - val_true_positives: 783.0000\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 772s 9s/step - loss: 0.3063 - accuracy: 0.8740 - true_positives: 2511.0000 - val_loss: 0.7642 - val_accuracy: 0.7335 - val_true_positives: 702.0000\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 754s 8s/step - loss: 0.3025 - accuracy: 0.8803 - true_positives: 2529.0000 - val_loss: 0.4431 - val_accuracy: 0.8213 - val_true_positives: 786.0000\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 754s 8s/step - loss: 0.2939 - accuracy: 0.8771 - true_positives: 2520.0000 - val_loss: 0.4522 - val_accuracy: 0.8192 - val_true_positives: 784.0000\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 752s 8s/step - loss: 0.2648 - accuracy: 0.8928 - true_positives: 2565.0000 - val_loss: 0.5915 - val_accuracy: 0.7576 - val_true_positives: 725.0000\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 757s 8s/step - loss: 0.2703 - accuracy: 0.8876 - true_positives: 2550.0000 - val_loss: 0.4264 - val_accuracy: 0.8412 - val_true_positives: 805.0000\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 751s 8s/step - loss: 0.2567 - accuracy: 0.9029 - true_positives: 2594.0000 - val_loss: 0.4671 - val_accuracy: 0.8150 - val_true_positives: 780.0000\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 750s 8s/step - loss: 0.2279 - accuracy: 0.9133 - true_positives: 2624.0000 - val_loss: 0.5692 - val_accuracy: 0.7994 - val_true_positives: 765.0000\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 764s 8s/step - loss: 0.2391 - accuracy: 0.9050 - true_positives: 2600.0000 - val_loss: 0.4669 - val_accuracy: 0.8443 - val_true_positives: 808.0000\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 756s 8s/step - loss: 0.2152 - accuracy: 0.9133 - true_positives: 2624.0000 - val_loss: 0.3818 - val_accuracy: 0.8683 - val_true_positives: 831.0000\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 754s 8s/step - loss: 0.2007 - accuracy: 0.9186 - true_positives: 2639.0000 - val_loss: 0.4688 - val_accuracy: 0.8380 - val_true_positives: 802.0000\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 750s 8s/step - loss: 0.1841 - accuracy: 0.9300 - true_positives: 2672.0000 - val_loss: 0.5054 - val_accuracy: 0.8495 - val_true_positives: 813.0000\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 758s 8s/step - loss: 0.1971 - accuracy: 0.9276 - true_positives: 2665.0000 - val_loss: 0.4728 - val_accuracy: 0.8506 - val_true_positives: 814.0000\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 754s 8s/step - loss: 0.1564 - accuracy: 0.9436 - true_positives: 2711.0000 - val_loss: 0.3889 - val_accuracy: 0.8725 - val_true_positives: 835.0000\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 752s 8s/step - loss: 0.1392 - accuracy: 0.9492 - true_positives: 2727.0000 - val_loss: 0.4212 - val_accuracy: 0.8840 - val_true_positives: 846.0000\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 756s 8s/step - loss: 0.1275 - accuracy: 0.9502 - true_positives: 2730.0000 - val_loss: 0.3690 - val_accuracy: 0.8945 - val_true_positives: 856.0000\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 755s 8s/step - loss: 0.1379 - accuracy: 0.9471 - true_positives: 2721.0000 - val_loss: 0.3836 - val_accuracy: 0.8809 - val_true_positives: 843.0000\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 756s 8s/step - loss: 0.1112 - accuracy: 0.9596 - true_positives: 2757.0000 - val_loss: 0.3676 - val_accuracy: 0.8871 - val_true_positives: 849.0000\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 758s 8s/step - loss: 0.1087 - accuracy: 0.9579 - true_positives: 2752.0000 - val_loss: 0.3669 - val_accuracy: 0.8976 - val_true_positives: 859.0000\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 750s 8s/step - loss: 0.1297 - accuracy: 0.9516 - true_positives: 2734.0000 - val_loss: 0.4435 - val_accuracy: 0.8892 - val_true_positives: 851.0000\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 763s 8s/step - loss: 0.1102 - accuracy: 0.9614 - true_positives: 2762.0000 - val_loss: 0.5260 - val_accuracy: 0.8495 - val_true_positives: 813.0000\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 751s 8s/step - loss: 0.1037 - accuracy: 0.9666 - true_positives: 2777.0000 - val_loss: 0.4063 - val_accuracy: 0.8871 - val_true_positives: 849.0000\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 756s 8s/step - loss: 0.0995 - accuracy: 0.9676 - true_positives: 2780.0000 - val_loss: 0.4188 - val_accuracy: 0.8924 - val_true_positives: 854.0000\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 753s 8s/step - loss: 0.0827 - accuracy: 0.9715 - true_positives: 2791.0000 - val_loss: 0.3864 - val_accuracy: 0.8882 - val_true_positives: 850.0000\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 758s 8s/step - loss: 0.0915 - accuracy: 0.9694 - true_positives: 2785.0000 - val_loss: 0.4343 - val_accuracy: 0.8777 - val_true_positives: 840.0000\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 757s 8s/step - loss: 0.0861 - accuracy: 0.9697 - true_positives: 2786.0000 - val_loss: 0.3955 - val_accuracy: 0.8934 - val_true_positives: 855.0000\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 752s 8s/step - loss: 0.0796 - accuracy: 0.9729 - true_positives: 2795.0000 - val_loss: 0.3789 - val_accuracy: 0.8997 - val_true_positives: 861.0000\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 761s 8s/step - loss: 0.0705 - accuracy: 0.9777 - true_positives: 2809.0000 - val_loss: 0.4039 - val_accuracy: 0.8955 - val_true_positives: 857.0000\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 756s 8s/step - loss: 0.0689 - accuracy: 0.9770 - true_positives: 2807.0000 - val_loss: 0.4039 - val_accuracy: 0.8976 - val_true_positives: 859.0000\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 752s 8s/step - loss: 0.0594 - accuracy: 0.9819 - true_positives: 2821.0000 - val_loss: 0.4063 - val_accuracy: 0.8976 - val_true_positives: 859.0000\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 753s 8s/step - loss: 0.0759 - accuracy: 0.9739 - true_positives: 2798.0000 - val_loss: 0.4060 - val_accuracy: 0.8955 - val_true_positives: 857.0000\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 755s 8s/step - loss: 0.0606 - accuracy: 0.9816 - true_positives: 2820.0000 - val_loss: 0.3945 - val_accuracy: 0.9039 - val_true_positives: 865.0000\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 761s 8s/step - loss: 0.0647 - accuracy: 0.9795 - true_positives: 2814.0000 - val_loss: 0.3965 - val_accuracy: 0.9007 - val_true_positives: 862.0000\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 751s 8s/step - loss: 0.0619 - accuracy: 0.9784 - true_positives: 2811.0000 - val_loss: 0.3957 - val_accuracy: 0.9028 - val_true_positives: 864.0000\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 755s 8s/step - loss: 0.0575 - accuracy: 0.9798 - true_positives: 2815.0000 - val_loss: 0.4018 - val_accuracy: 0.9060 - val_true_positives: 867.0000\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 750s 8s/step - loss: 0.0726 - accuracy: 0.9781 - true_positives: 2810.0000 - val_loss: 0.4040 - val_accuracy: 0.9007 - val_true_positives: 862.0000\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 760s 8s/step - loss: 0.0566 - accuracy: 0.9805 - true_positives: 2817.0000 - val_loss: 0.4109 - val_accuracy: 0.9007 - val_true_positives: 862.0000\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 760s 8s/step - loss: 0.0658 - accuracy: 0.9788 - true_positives: 2812.0000 - val_loss: 0.4076 - val_accuracy: 0.9007 - val_true_positives: 862.0000\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 751s 8s/step - loss: 0.0519 - accuracy: 0.9850 - true_positives: 2830.0000 - val_loss: 0.4012 - val_accuracy: 0.9049 - val_true_positives: 866.0000\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 760s 8s/step - loss: 0.0637 - accuracy: 0.9788 - true_positives: 2812.0000 - val_loss: 0.4016 - val_accuracy: 0.8986 - val_true_positives: 860.0000\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 757s 8s/step - loss: 0.0592 - accuracy: 0.9802 - true_positives: 2816.0000 - val_loss: 0.3989 - val_accuracy: 0.9028 - val_true_positives: 864.0000\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 783s 9s/step - loss: 0.0466 - accuracy: 0.9840 - true_positives: 2827.0000 - val_loss: 0.3993 - val_accuracy: 0.9028 - val_true_positives: 864.0000\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 826s 9s/step - loss: 0.0677 - accuracy: 0.9784 - true_positives: 2811.0000 - val_loss: 0.4063 - val_accuracy: 0.9039 - val_true_positives: 865.0000\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 761s 8s/step - loss: 0.0583 - accuracy: 0.9826 - true_positives: 2823.0000 - val_loss: 0.3976 - val_accuracy: 0.9049 - val_true_positives: 866.0000\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 752s 8s/step - loss: 0.0497 - accuracy: 0.9840 - true_positives: 2827.0000 - val_loss: 0.3961 - val_accuracy: 0.9039 - val_true_positives: 865.0000\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 753s 8s/step - loss: 0.0646 - accuracy: 0.9781 - true_positives: 2810.0000 - val_loss: 0.3957 - val_accuracy: 0.9039 - val_true_positives: 865.0000\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 782s 9s/step - loss: 0.0460 - accuracy: 0.9857 - true_positives: 2832.0000 - val_loss: 0.3956 - val_accuracy: 0.9039 - val_true_positives: 865.0000\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 813s 9s/step - loss: 0.0722 - accuracy: 0.9753 - true_positives: 2802.0000 - val_loss: 0.3897 - val_accuracy: 0.9049 - val_true_positives: 866.0000\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 824s 9s/step - loss: 0.0480 - accuracy: 0.9857 - true_positives: 2832.0000 - val_loss: 0.3954 - val_accuracy: 0.9049 - val_true_positives: 866.0000\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 802s 9s/step - loss: 0.0579 - accuracy: 0.9805 - true_positives: 2817.0000 - val_loss: 0.3975 - val_accuracy: 0.9049 - val_true_positives: 866.0000\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 846s 9s/step - loss: 0.0518 - accuracy: 0.9850 - true_positives: 2830.0000 - val_loss: 0.3973 - val_accuracy: 0.9070 - val_true_positives: 868.0000\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1018s 11s/step - loss: 0.0597 - accuracy: 0.9833 - true_positives: 2825.0000 - val_loss: 0.3981 - val_accuracy: 0.9039 - val_true_positives: 865.0000\n",
      "Epoch 54/100\n",
      "15/90 [====>.........................] - ETA: 12:03 - loss: 0.0773 - accuracy: 0.9688 - true_positives: 465.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ff671740943d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(datagen.flow_from_directory(\"../data/preprocessed/img/Train\",\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                 \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                 \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(datagen.flow_from_directory(\"../data/preprocessed/img/Train\",\n",
    "                                                target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                                class_mode='categorical',\n",
    "                                                batch_size=32,\n",
    "                                                shuffle=True),\n",
    "                    epochs=100, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T16:18:36.429987Z",
     "start_time": "2021-03-22T16:18:01.361Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:17:13.001054Z",
     "start_time": "2021-03-23T08:16:05.314821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9999976e-01, 1.9311439e-07],\n",
       "       [9.9999881e-01, 1.1959802e-06],\n",
       "       [1.0000000e+00, 3.3328206e-08],\n",
       "       ...,\n",
       "       [4.5619577e-06, 9.9999547e-01],\n",
       "       [9.9928492e-01, 7.1511389e-04],\n",
       "       [9.9996257e-01, 3.7436563e-05]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T20:53:50.195558Z",
     "start_time": "2021-03-22T20:53:50.172705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:17:13.077454Z",
     "start_time": "2021-03-23T08:17:13.004118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[377,  77],\n",
       "       [ 19, 484]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(np.argmax(y_test, axis=-1), np.argmax(y_pred, axis=-1))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:17:13.608105Z",
     "start_time": "2021-03-23T08:17:13.083086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.heatmap(cm, annot=True, cmap=\"Blues\", fmt='d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:17:13.680643Z",
     "start_time": "2021-03-23T08:17:13.620389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Begnin       0.95      0.83      0.89       454\n",
      "   Malignant       0.86      0.96      0.91       503\n",
      "\n",
      "    accuracy                           0.90       957\n",
      "   macro avg       0.91      0.90      0.90       957\n",
      "weighted avg       0.91      0.90      0.90       957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=-1),\n",
    "                            np.argmax(y_pred, axis=-1),\n",
    "                            target_names=[\"Begnin\", \"Malignant\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:18:09.593683Z",
     "start_time": "2021-03-23T08:17:13.691508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: efficientnet_b0_v2/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('tf': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f774a9317f8c9478287f3aa77710d9959114b97a9f467c5fb91a7e7bca35fa13"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}